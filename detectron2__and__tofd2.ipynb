{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wqX6SrXblKlT",
    "outputId": "7f8fa123-85dd-4980-e39b-ae07a7b1611b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-kgg8pg3z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-kgg8pg3z\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit b1c43ffbc995426a9a6b5c667730091a384e0fa4\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
      "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.67.1)\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n",
      "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
      "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting black (from detectron2==0.6)\n",
      "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
      "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.68.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=5974710 sha256=a47cc56ea1ba818dcfc8d9edb71cc2b73f8318b8b33d6fad55285eb685805301\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2zp2xd00/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=fed08820413426185fc4d2c9c9cb00f3b416cf3a38a8bae7ae6c4755eb5abd5b\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=0df8a16669750e4e43c818a8160fabf20ccae2e623ea7debddc22c22ea96a7b9\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "ed47a3e0dd3746a8b1196bff3ac63e8e",
       "pip_warning": {
        "packages": [
         "pydevd_plugins"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How do you install Detectron2 using pip and check the version of Detectron2\n",
    "\n",
    "#!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "-irPFGVyldmA",
    "outputId": "cf34287a-0659-46d9-c7d0-f97285f38d5b"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Config file 'detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml' does not exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be592004dbf3>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Create configuration for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the appropriate config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWEIGHTS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\u001b[0m  \u001b[0;31m# Pre-trained model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROI_HEADS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCORE_THRESH_TEST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m  \u001b[0;31m# Set a threshold for this model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/config/config.py\u001b[0m in \u001b[0;36mmerge_from_file\u001b[0;34m(self, cfg_filename, allow_unsafe)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mallow_unsafe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mallow\u001b[0m \u001b[0munsafe\u001b[0m \u001b[0myaml\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mPathManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Config file '{cfg_filename}' does not exist!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloaded_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_yaml_with_base\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unsafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_unsafe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloaded_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Config file 'detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml' does not exist!"
     ]
    }
   ],
   "source": [
    "#Q2  How do you perform inference with Detectron2 using an online image\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "\n",
    "image_url = \"/content/pexels-marx-ilagan-616381.jpg\" \n",
    "response = cv2.imread(image_url)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  \n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "outputs = predictor(image)\n",
    "\n",
    "\n",
    "v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "output_image = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(output_image.get_image()[:, :, ::-1])  \n",
    "plt.axis('off')\n",
    "plt.title('Detectron2 Inference Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CclbJkNSm2iF"
   },
   "outputs": [],
   "source": [
    "#Q2  How do you perform inference with Detectron2 using an online image\n",
    "\n",
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import os\n",
    "\n",
    "\n",
    "image_url = \"/content/pexels-marx-ilagan-616381.jpg\"  \n",
    "image = cv2.imread(image_url)\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "detectron2_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "config_file_path = os.path.join(detectron2_path, 'configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml')\n",
    "\n",
    "cfg.merge_from_file(config_file_path)\n",
    "\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "outputs = predictor(image)\n",
    "\n",
    "\n",
    "v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "output_image = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(output_image.get_image()[:, :, ::-1])  \n",
    "plt.axis('off')\n",
    "plt.title('Detectron2 Inference Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-lyWfbtSn3W9"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Q3 How do you visualize evaluation metrics in Detectron2, such as training loss\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.utils.events import EventStorage\n",
    "\n",
    "# Step 1: Setup configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  \n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  \n",
    "cfg.DATASETS.TRAIN = (\"your_train_dataset_name\",)  \n",
    "cfg.DATASETS.TEST = (\"your_val_dataset_name\",)  \n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  \n",
    "cfg.SOLVER.MAX_ITER = 3000    \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  \n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "\n",
    "losses = []\n",
    "with EventStorage() as storage:\n",
    "    for iteration in range(cfg.SOLVER.MAX_ITER):\n",
    "        trainer.run_step()  \n",
    "\n",
    "        \n",
    "        if iteration % 10 == 0:  \n",
    "            loss_value = trainer.storage.history[\"loss\"].latest()  \n",
    "            losses.append(loss_value)\n",
    "            storage.put_scalar(\"loss\", loss_value)\n",
    "            storage.step()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(len(losses)), losses, label='Training Loss')\n",
    "plt.title('Training Loss Over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "image_url = \"th(1)eed.jpg\" \n",
    "response = requests.get(image_url)\n",
    "image = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(image)\n",
    "\n",
    "# Visualize the results on the online image\n",
    "v = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "output_image = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "# Display the output image with bounding boxes and labels\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(output_image.get_image()[:, :, ::-1])  # Convert BGR to RGB for displaying\n",
    "plt.axis('off')\n",
    "plt.title('Detectron2 Inference Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UG7cFTWNo1ag"
   },
   "outputs": [],
   "source": [
    "#Q4 How do you run inference with TFOD2 on an online image\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\"\n",
    "model_dir = tf.keras.utils.get_file('faster_rcnn_resnet50_coco', model_url, untar=True)\n",
    "model_dir = model_dir + \"/frozen_inference_graph.pb\"\n",
    "\n",
    "\n",
    "detect_fn = tf.saved_model.load(model_dir)\n",
    "\n",
    "\n",
    "def load_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    image_np = np.array(image)\n",
    "    return image_np\n",
    "\n",
    "# Function to run inference on the image\n",
    "def run_inference_for_single_image(model, image):\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    detections = model(input_tensor)\n",
    "    return detections\n",
    "\n",
    "def visualize_detections(image_np, detections):\n",
    "    \n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "   \n",
    "    threshold = 0.5\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            (ymin, xmin, ymax, xmax) = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin * image_np.shape[1], ymin * image_np.shape[0]),\n",
    "                                                (xmax - xmin) * image_np.shape[1],\n",
    "                                                (ymax - ymin) * image_np.shape[0],\n",
    "                                                fill=False, color='red', linewidth=2))\n",
    "            plt.text(xmin * image_np.shape[1], ymin * image_np.shape[0],\n",
    "                     f'Class: {classes[i]}, Score: {scores[i]:.2f}',\n",
    "                     bbox=dict(facecolor='yellow', alpha=0.5), fontsize=12)\n",
    "\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\" \n",
    "image_np = load_image(image_url)\n",
    "\n",
    "\n",
    "detections = run_inference_for_single_image(detect_fn, image_np)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_np)\n",
    "visualize_detections(image_np, detections)\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kd5Z1Ax6pTej"
   },
   "outputs": [],
   "source": [
    "#Q5 How do you install TensorFlow Object Detection API in Jupyter Notebook\n",
    "\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "\n",
    "!git clone https://github.com/tensorflow/models.git\n",
    "\n",
    "!apt-get install -y protobuf-compiler  \n",
    "\n",
    "\n",
    "%cd models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install .\n",
    "\n",
    "\n",
    "!pip install cython\n",
    "!pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
    "\n",
    "import object_detection\n",
    "print(\"TensorFlow Object Detection API installed successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isabaUIlpThd"
   },
   "outputs": [],
   "source": [
    "#Q6 > How can you load a pre-trained TensorFlow Object Detection model\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2017_11_17.tar.gz\"\n",
    "model_dir = tf.keras.utils.get_file('faster_rcnn_resnet50_coco', model_url, untar=True)\n",
    "\n",
    "\n",
    "model_dir = model_dir + \"/frozen_inference_graph.pb\"\n",
    "detect_fn = tf.saved_model.load(model_dir)\n",
    "\n",
    "\n",
    "def load_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    image_np = np.array(image)\n",
    "    return image_np\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...] \n",
    "    detections = model(input_tensor)\n",
    "    return detections\n",
    "\n",
    "def visualize_detections(image_np, detections):\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    threshold = 0.5  \n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            (ymin, xmin, ymax, xmax) = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin * image_np.shape[1], ymin * image_np.shape[0]),\n",
    "                                                (xmax - xmin) * image_np.shape[1],\n",
    "                                                (ymax - ymin) * image_np.shape[0],\n",
    "                                                fill=False, color='red', linewidth=2))\n",
    "            plt.text(xmin * image_np.shape[1], ymin * image_np.shape[0],\n",
    "                     f'Class: {classes[i]}, Score: {scores[i]:.2f}',\n",
    "                     bbox=dict(facecolor='yellow', alpha=0.5), fontsize=12)\n",
    "\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\" \n",
    "image_np = load_image(image_url)\n",
    "\n",
    "\n",
    "detections = run_inference_for_single_image(detect_fn, image_np)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_np)\n",
    "visualize_detections(image_np, detections)\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlolD60HpTkF"
   },
   "outputs": [],
   "source": [
    "#Q7 How do you preprocess an image from the web for TFOD2 inference\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/faster_rcnn_resnet50_coco_2017_11_17.tar.gz\"\n",
    "model_dir = tf.keras.utils.get_file('faster_rcnn_resnet50_coco', model_url, untar=True)\n",
    "model_dir = model_dir + \"/frozen_inference_graph.pb\"\n",
    "detect_fn = tf.saved_model.load(model_dir)\n",
    "\n",
    "def load_and_preprocess_image(image_url):\n",
    "   \n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    image = image.resize((640, 480))\n",
    "\n",
    "    image_np = np.array(image) / 255.0 \n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "    return input_tensor\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "    detections = model(image)\n",
    "    return detections\n",
    "\n",
    "\n",
    "def visualize_detections(image_np, detections):\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    threshold = 0.5  \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np)\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            (ymin, xmin, ymax, xmax) = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin * image_np.shape[1], ymin * image_np.shape[0]),\n",
    "                                                (xmax - xmin) * image_np.shape[1],\n",
    "                                                (ymax - ymin) * image_np.shape[0],\n",
    "                                                fill=False, color='red', linewidth=2))\n",
    "            plt.text(xmin * image_np.shape[1], ymin * image_np.shape[0],\n",
    "                     f'Class: {classes[i]}, Score: {scores[i]:.2f}',\n",
    "                     bbox=dict(facecolor='yellow', alpha=0.5), fontsize=12)\n",
    "\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\" \n",
    "input_tensor = load_and_preprocess_image(image_url)\n",
    "\n",
    "\n",
    "detections = run_inference_for_single_image(detect_fn, input_tensor)\n",
    "\n",
    "\n",
    "visualize_detections(np.array(Image.open(BytesIO(requests.get(image_url).content))), detections)\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjqSmLR3pTmu"
   },
   "outputs": [],
   "source": [
    "#Q8  How do you visualize bounding boxes for detected objects in TFOD2 inference\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/faster_rcnn_resnet50_coco_2017_11_17.tar.gz\"\n",
    "model_dir = tf.keras.utils.get_file('faster_rcnn_resnet50_coco', model_url, untar=True)\n",
    "model_dir = model_dir + \"/frozen_inference_graph.pb\"\n",
    "detect_fn = tf.saved_model.load(model_dir)\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_url):\n",
    "    \n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    \n",
    "    image_np = np.array(image) / 255.0 \n",
    "\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]  \n",
    "\n",
    "    return input_tensor, image_np\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "    detections = model(image)\n",
    "    return detections\n",
    "\n",
    "\n",
    "def visualize_detections(image_np, detections):\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    threshold = 0.5  \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np)\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            (ymin, xmin, ymax, xmax) = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin * image_np.shape[1], ymin * image_np.shape[0]),\n",
    "                                                (xmax - xmin) * image_np.shape[1],\n",
    "                                                (ymax - ymin) * image_np.shape[0],\n",
    "                                                fill=False, color='red', linewidth=2))\n",
    "            plt.text(xmin * image_np.shape[1], ymin * image_np.shape[0],\n",
    "                     f'Class: {classes[i]}, Score: {scores[i]:.2f}',\n",
    "                     bbox=dict(facecolor='yellow', alpha=0.5), fontsize=12)\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\"  \n",
    "input_tensor, original_image_np = load_and_preprocess_image(image_url)\n",
    "\n",
    "\n",
    "detections = run_inference_for_single_image(detect_fn, input_tensor)\n",
    "\n",
    "\n",
    "visualize_detections(original_image_np, detections)\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFURFFsZpTpg"
   },
   "outputs": [],
   "source": [
    "#Q9 How do you define classes for custom training in TFOD2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "classes = ['class_name_1', 'class_name_2', 'class_name_3']\n",
    "label_map_path = 'label_map.pbtxt'\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    for i, class_name in enumerate(classes, start=1):\n",
    "        f.write(f\"item {{\\n  id: {i}\\n  name: '{class_name}'\\n}}\\n\")\n",
    "\n",
    "config_path = 'models/research/object_detection/configs/tf2/faster_rcnn_resnet50_coco.config'\n",
    "pipeline_config = tf.io.gfile.GFile(config_path, \"r\").read()\n",
    "pipeline_config = pipeline_config.replace('num_classes: 90', f'num_classes: {len(classes)}')\n",
    "\n",
    "\n",
    "with tf.io.gfile.GFile(config_path, \"w\") as f:\n",
    "    f.write(pipeline_config)\n",
    "\n",
    "print(\"Label map and configuration updated for custom training.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_oqoktopTsW"
   },
   "outputs": [],
   "source": [
    "#Q10 How do you define classes for custom training in TFOD2\n",
    "\n",
    "classes = ['class_name_1', 'class_name_2', 'class_name_3']\n",
    "label_map_path = 'label_map.pbtxt'\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    for i, class_name in enumerate(classes, start=1):\n",
    "        f.write(f\"item {{\\n  id: {i}\\n  name: '{class_name}'\\n}}\\n\")\n",
    "\n",
    "config_path = 'models/research/object_detection/configs/tf2/faster_rcnn_resnet50_coco.config'\n",
    "pipeline_config = tf.io.gfile.GFile(config_path, \"r\").read()\n",
    "pipeline_config = pipeline_config.replace('num_classes: 90', f'num_classes: {len(classes)}')\n",
    "\n",
    "with tf.io.gfile.GFile(config_path, \"w\") as f:\n",
    "    f.write(pipeline_config)\n",
    "\n",
    "print(\"Label map and configuration updated for custom training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78pvyw75pTvU"
   },
   "outputs": [],
   "source": [
    "#Q11 How do you resize an image before detecting object1\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_url = \"http://download.tensorflow.org/models/faster_rcnn_resnet50_coco_2017_11_17.tar.gz\"\n",
    "model_dir = tf.keras.utils.get_file('faster_rcnn_resnet50_coco', model_url, untar=True)\n",
    "detect_fn = tf.saved_model.load(model_dir + \"/frozen_inference_graph.pb\")\n",
    "\n",
    "def load_and_preprocess_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    image = image.resize((640, 640))\n",
    "    image_np = np.array(image) / 255.0  \n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...] \n",
    "\n",
    "    return input_tensor, image_np\n",
    "\n",
    "def run_inference_for_single_image(model, image):\n",
    "    detections = model(image)\n",
    "    return detections\n",
    "\n",
    "def visualize_detections(image_np, detections):\n",
    "    boxes = detections['detection_boxes'][0].numpy()\n",
    "    classes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "    scores = detections['detection_scores'][0].numpy()\n",
    "\n",
    "    threshold = 0.5 \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_np)\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i] > threshold:\n",
    "            box = boxes[i]\n",
    "            (ymin, xmin, ymax, xmax) = box\n",
    "            plt.gca().add_patch(plt.Rectangle((xmin * image_np.shape[1], ymin * image_np.shape[0]),\n",
    "                                                (xmax - xmin) * image_np.shape[1],\n",
    "                                                (ymax - ymin) * image_np.shape[0],\n",
    "                                                fill=False, color='red', linewidth=2))\n",
    "            plt.text(xmin * image_np.shape[1], ymin * image_np.shape[0],\n",
    "                     f'Class: {classes[i]}, Score: {scores[i]:.2f}',\n",
    "                     bbox=dict(facecolor='yellow', alpha=0.5), fontsize=12)\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\"  \n",
    "input_tensor, original_image_np = load_and_preprocess_image(image_url)\n",
    "\n",
    "detections = run_inference_for_single_image(detect_fn, input_tensor)\n",
    "\n",
    "visualize_detections(original_image_np, detections)\n",
    "plt.axis('off')\n",
    "plt.title('Object Detection Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOnwe1kspTyo"
   },
   "outputs": [],
   "source": [
    "#Q12 > How can you apply a color filter (e.g., red filter) to an image?\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "image = image.convert('RGB')\n",
    "\n",
    "red_filter = Image.new('RGB', image.size, (255, 0, 0))  \n",
    "\n",
    "filtered_image_pillow = Image.blend(image, red_filter, alpha=0.5)  # Adjust alpha for intensity\n",
    "\n",
    "# Save or display the result using Pillow\n",
    "filtered_image_pillow.show()  # Display the image\n",
    "filtered_image_pillow.save('path/to/save/filtered_image_pillow.jpg')  # Save the filtered image\n",
    "\n",
    "# Using OpenCV to apply a red filter\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image_cv = cv2.imread(image_path)\n",
    "\n",
    "# Create a red filter (BGR format)\n",
    "red_filter_cv = np.zeros_like(image_cv)\n",
    "red_filter_cv[:, :, 2] = 255  # Set the red channel to maximum\n",
    "\n",
    "# Apply the red filter using OpenCV\n",
    "filtered_image_cv = cv2.addWeighted(image_cv, 0.5, red_filter_cv, 0.5, 0)  # Adjust weights for intensity\n",
    "\n",
    "# Display the result using OpenCV\n",
    "cv2.imshow('Filtered Image (OpenCV)', filtered_image_cv)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the filtered image using OpenCV\n",
    "cv2.imwrite('path/to/save/filtered_image_cv.jpg', filtered_image_cv)  # Save the filtered image\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
